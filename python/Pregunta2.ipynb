{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simulo datos\n",
    "np.random.seed(42)\n",
    "n = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps1 = np.random.normal(0, 1, n)\n",
    "eps2 = np.random.normal(0, 1, n)\n",
    "eps3 = np.random.normal(0, 1, n)\n",
    "epsx = np.random.normal(0, 1, n)\n",
    "epsy = np.random.normal(0, 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = eps1\n",
    "Z3 = eps3\n",
    "Z2 = Z3 + eps2\n",
    "X = Z1 + Z2 + epsx\n",
    "Y = X + Z1 + Z2 + Z3 + epsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Y': Y, 'X': X, 'Z1': Z1, 'Z2': Z2, 'Z3': Z3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ols(vars_x):\n",
    "    Xmat = sm.add_constant(df[vars_x])\n",
    "    model = sm.OLS(df['Y'], Xmat).fit()\n",
    "    beta = model.params['X']\n",
    "    se = model.bse['X']\n",
    "    z = 2.5758  # IC al 99%\n",
    "    ci_low, ci_high = beta - z * se, beta + z * se\n",
    "    return model, beta, se, (ci_low, ci_high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = [\n",
    "    [\"X\"],\n",
    "    [\"X\", \"Z1\"],\n",
    "    [\"X\", \"Z2\"],\n",
    "    [\"X\", \"Z1\", \"Z2\"],\n",
    "    [\"X\", \"Z1\", \"Z2\", \"Z3\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for m in modelos:\n",
    "    res, b, se, ci = run_ols(m)\n",
    "    results.append({\"Vars\": m, \"Beta_X\": b, \"SE\": se, \"CI_low\": ci[0], \"CI_high\": ci[1], \"Model\": res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = pd.DataFrame(results)\n",
    "tabla[\"Regresión\"] = [\"Y~X\", \"Y~X+Z1\", \"Y~X+Z2\", \"Y~X+Z1+Z2\", \"Y~X+Z1+Z2+Z3\"]\n",
    "tabla = tabla[[\"Regresión\", \"Beta_X\", \"SE\", \"CI_low\", \"CI_high\"]]\n",
    "print(\"RESULTADOS DE LAS REGRESIONES (IC 99%)\")\n",
    "print(tabla.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "xpos = np.arange(len(tabla))\n",
    "plt.errorbar(xpos, tabla[\"Beta_X\"],\n",
    "             yerr=[tabla[\"Beta_X\"] - tabla[\"CI_low\"], tabla[\"CI_high\"] - tabla[\"Beta_X\"]],\n",
    "             fmt='o', color='orange', capsize=5)\n",
    "plt.axhline(1, color='black', linestyle='--', label='Valor verdadero = 1')\n",
    "plt.xticks(xpos, tabla[\"Regresión\"])\n",
    "plt.ylabel(\"Estimador de β_X\")\n",
    "plt.title(\"Estimaciones del efecto de X sobre Y con IC 99%\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Estimaciones.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico muestra las estimaciones del efecto de X sobre Y bajo distintas especificaciones de control. Se observa que los modelos (1) Y~X, (2) Y~X+Z1 y (3) Y~X+Z2 sobreestiman el efecto verdadero (β=1), indicando sesgo por variables omitidas, ya que al no controlar simultáneamente por Z1 y Z2, los caminos de confusión permanecen abiertos. En cambio, las regresiones (4) Y~X+Z1+Z2 y (5) Y~X+Z1+Z2+Z3 producen estimaciones cercanas al valor real, confirmando que incluir Z1 y Z2 es suficiente para identificar correctamente el efecto causal. Además, al añadir Z3 no se mejora la precisión ni el sesgo, sino que se amplía ligeramente el intervalo de confianza debido a multicolinealidad innecesaria. En síntesis, controlar por Z1 y Z2 basta para obtener una estimación insesgada y eficiente del efecto de X sobre Y."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
